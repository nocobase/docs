"use strict";(self.webpackChunknocobase_docs=self.webpackChunknocobase_docs||[]).push([[40173],{17057:function(d,e,_){_.r(e);var s=_(572269),u=_(793359),c=_(861788),m=_(719977),h=_(20190),E=_(24268),M=_(496057),P=_(585939),x=_(28484),D=_(635206),O=_(375553),v=_(156266),I=_(572333),t=_(841118),L=_(39297),j=_(868526),f=_(605019),i=_(614651),r=_(280936),a=_(667294),o=_(619585),n=_(785893);function l(){return(0,n.jsx)(i.dY,{children:(0,n.jsx)(a.Suspense,{fallback:(0,n.jsx)(r.Z,{}),children:(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)("div",{className:"markdown",children:(0,n.jsxs)("h1",{id:"llm-service-management",children:[(0,n.jsx)("a",{"aria-hidden":"true",tabIndex:"-1",href:"#llm-service-management",children:(0,n.jsx)("span",{className:"icon icon-link"})}),"LLM Service Management"]})}),(0,n.jsx)(t.Z,{name:"ai"}),(0,n.jsxs)("div",{className:"markdown",children:[(0,n.jsxs)("h2",{id:"introduction",children:[(0,n.jsx)("a",{"aria-hidden":"true",tabIndex:"-1",href:"#introduction",children:(0,n.jsx)("span",{className:"icon icon-link"})}),"Introduction"]}),(0,n.jsx)("p",{children:o.texts[0].value}),(0,n.jsx)("p",{children:(0,n.jsx)("img",{src:"https://static-docs.nocobase.com/202503021832046.png",alt:""})}),(0,n.jsxs)("h2",{id:"configuring",children:[(0,n.jsx)("a",{"aria-hidden":"true",tabIndex:"-1",href:"#configuring",children:(0,n.jsx)("span",{className:"icon icon-link"})}),"Configuring"]}),(0,n.jsx)("p",{children:o.texts[1].value}),(0,n.jsx)("p",{children:(0,n.jsx)("img",{src:"https://static-docs.nocobase.com/202503032320237.png",alt:""})})]})]})})})}e.default=l},619585:function(d,e,_){_.r(e),_.d(e,{texts:function(){return s}});const s=[{value:`Before using AI features, you need to first integrate an online LLM service. NocoBase supports integrating online LLM services using multiple API protocols.
Currently, the open-source version supports mainstream LLM protocols, such as OpenAI and DeepSeek, or LLM services with the same calling format, which can be integrated through the API interfaces provided by the LLM service providers.
The enterprise version also supports Ollama local models, and enterprise users can also contact us to extend support for more API protocols as needed.`,paraId:0,tocIndex:1},{value:"Fill in the online service information according to the selected API protocol, usually requiring input of an API key and Base URL.",paraId:1,tocIndex:2}]}}]);
